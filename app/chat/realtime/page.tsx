"use client"

import React, { FC, useState, useRef, useCallback, useEffect } from "react"
import { cn } from "@/lib/utils" // (cn) Ø´Ù…Ø§ Ø§Ø² Ù‚Ø¨Ù„ Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
import { toast, Toaster } from "sonner" // Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø®Ø·Ø§Ù‡Ø§
import { motion, AnimatePresence } from "framer-motion"

const remoteLog = (message: string) => {
  // Ù„Ø§Ú¯ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„ Ù…Ø­Ù„ÛŒ (Ø§Ú¯Ø± inspect Ø´Ø§Ù†Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø² Ø´Ø¯Ù† Ø¯Ø§Ø´Øª)
  console.log(message)

  // Ø§Ø±Ø³Ø§Ù„ Ù„Ø§Ú¯ Ø¨Ù‡ Ø³Ø±ÙˆØ± Vercel
  fetch("/api/log", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    // Ù…Ø§ Ù¾ÛŒØ§Ù… Ø±Ø§ Ø¨Ø§ [VoiceUI] Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ø¯Ø± Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Vercel Ù…Ø´Ø®Øµ Ø¨Ø§Ø´Ø¯
    body: JSON.stringify({ message: `[VoiceUI] ${message}` })
  }).catch(err => console.error("Remote log failed:", err)) // Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù„Ø§Ú¯ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
}

const CircularAudioVisualizer: FC<{ volume: number }> = ({ volume }) => {
  // Ø­Ø¬Ù… ØµØ¯Ø§ Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ù…Ù‚Ø¯Ø§Ø± Ù„Ú¯Ø§Ø±ÛŒØªÙ…ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ù†ÙˆØ³Ø§Ù† Ø²ÛŒØ¨Ø§ØªØ± Ø¨Ø§Ø´Ø¯
  const scale = Math.log(1 + volume * 2) * 0.5 + 1
  const opacity = Math.min(volume / 50, 0.5)

  return (
    <div className="relative flex size-64 items-center justify-center">
      {/* Ù‡Ø§Ù„Ù‡ Ø¨ÛŒØ±ÙˆÙ†ÛŒ */}
      <motion.div
        className="absolute size-full rounded-full border border-blue-500/30 bg-blue-500/10"
        animate={{
          scale: scale * 1.1,
          opacity: opacity * 0.8
        }}
        transition={{ duration: 0.1, ease: "easeOut" }}
      />
      {/* Ù‡Ø§Ù„Ù‡ Ù…ÛŒØ§Ù†ÛŒ */}
      <motion.div
        className="absolute size-48 rounded-full border border-blue-500/50 bg-blue-500/20"
        animate={{
          scale: scale,
          opacity: opacity
        }}
        transition={{ duration: 0.1, ease: "easeOut" }}
      />
      {/* Ø¯Ú©Ù…Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ø¯Ø§Ø®Ù„ÛŒ */}
      <div className="flex size-32 items-center justify-center rounded-full bg-gradient-to-br from-blue-500 to-indigo-600 shadow-lg">
        <svg
          className="size-16 text-white"
          viewBox="0 0 24 24"
          fill="none"
          xmlns="http://www.w3.org/2000/svg"
        >
          <path
            d="M12 1a3 3 0 00-3 3v8a3 3 0 006 0V4a3 3 0 00-3-3z"
            fill="currentColor"
          />
          <path
            d="M19 10v2a7 7 0 01-14 0v-2H3v2a9 9 0 008 8.94V23h2v-2.06A9 9 0 0021 12v-2h-2z"
            fill="currentColor"
          />
        </svg>
      </div>
    </div>
  )
}

// ------------------------------------------------------------------
// Ù‡ÙˆÚ© ÙˆÛŒÚ˜ÙˆØ§Ù„Ø§ÛŒØ²Ø± (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ø®Ø·Ø§ÛŒ TS(2345))
// ------------------------------------------------------------------
const useAudioVisualizer = (stream: MediaStream | null) => {
  const [volume, setVolume] = useState(0)
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyzerRef = useRef<AnalyserNode | null>(null)
  const animationFrameRef = useRef<number | null>(null)

  useEffect(() => {
    if (!stream) {
      if (audioContextRef.current) {
        audioContextRef.current.close().catch(console.error)
        audioContextRef.current = null
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
      setVolume(0)
      return
    }

    if (!audioContextRef.current) {
      const audioContext = new (window.AudioContext ||
        (window as any).webkitAudioContext)()
      const analyzer = audioContext.createAnalyser()
      analyzer.fftSize = 256
      const source = audioContext.createMediaStreamSource(stream)
      source.connect(analyzer)
      analyzerRef.current = analyzer
      audioContextRef.current = audioContext
    }

    const analyze = () => {
      const analyzer = analyzerRef.current

      if (analyzer) {
        // âœ… [Ø§ØµÙ„Ø§Ø­ TS(2345)]
        // ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ Ù…ÙˆÙ‚Øª Ø¨Ø§ ØªØ§ÛŒÙ¾ ØµØ­ÛŒØ­ Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ… ØªØ§ ØªØ§Ø¨Ø¹ Ø¨ØªÙˆØ§Ù†Ø¯ Ø¯Ø± Ø¢Ù† Ø¨Ù†ÙˆÛŒØ³Ø¯
        const tempArray = new Uint8Array(analyzer.frequencyBinCount)
        analyzer.getByteFrequencyData(tempArray)

        const sum = tempArray.reduce((a, b) => a + b, 0)
        const avg = sum / tempArray.length
        setVolume(avg)
      }
      animationFrameRef.current = requestAnimationFrame(analyze)
    }

    analyze()

    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
      if (audioContextRef.current) {
        audioContextRef.current.close().catch(console.error)
        audioContextRef.current = null
      }
    }
  }, [stream])

  return volume
}

// ------------------------------------------------------------------
// ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ØªÙˆÚ©Ù† (Ø®ÙˆØ§Ù†Ø¯Ù† Ø§Ø² localStorage)
// ------------------------------------------------------------------
// const getSupabaseToken = (): string | null => {
//     if (typeof window !== "undefined") {
//         const token = localStorage.getItem("supabase-access-token")
//         console.log(
//             token
//                 ? "âœ… Token found in localStorage."
//                 : "âŒ Token not found in localStorage."
//         )
//         return token
//     }
//     return null
// }

// ------------------------------------------------------------------
// Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª Ø§ØµÙ„ÛŒ ØµÙØ­Ù‡
// ------------------------------------------------------------------
const RealtimeVoicePage: FC = () => {
  const [status, setStatus] = useState<"idle" | "connecting" | "connected">(
    "idle"
  )
  const [model, setModel] = useState<string>("gpt-4o-realtime-preview")

  // âœ… [Ø§ØµÙ„Ø§Ø­ Ø§ØµÙ„ÛŒ Û±]
  // ÛŒÚ© state Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ØªÙˆÚ©Ù† Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
  const [supabaseToken, setSupabaseToken] = useState<string | null>(null)

  const dataChannelRef = useRef<RTCDataChannel | null>(null)
  const [userStream, setUserStream] = useState<MediaStream | null>(null)
  const [modelStream, setModelStream] = useState<MediaStream | null>(null)
  const peerConnectionRef = useRef<RTCPeerConnection | null>(null)

  const userVolume = useAudioVisualizer(userStream)
  const modelVolume = useAudioVisualizer(modelStream)
  const combinedVolume = Math.max(userVolume, modelVolume)
  useEffect(() => {
    remoteLog("Page component mounted. Adding global error listener.")

    const handleError = (event: ErrorEvent) => {
      // Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ú©Ø±Ø´ Ø¬Ø§ÙˆØ§ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¯Ø± ØµÙØ­Ù‡ Ø±Ø§ Ù„Ø§Ú¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
      remoteLog(
        `!!! GLOBAL CRASH !!! Message: ${event.message}, File: ${event.filename}, Line: ${event.lineno}`
      )
    }

    window.addEventListener("error", handleError)

    return () => {
      window.removeEventListener("error", handleError)
    }
  }, [])

  useEffect(() => {
    remoteLog("Token polling effect started.")
    const intervalId = setInterval(() => {
      const token = (window as any).SUPABASE_ACCESS_TOKEN
      remoteLog(
        `Polling... window token is: ${token ? token.substring(0, 10) + "..." : "null"}`
      )

      if (typeof window !== "undefined" && token) {
        remoteLog("SUCCESS! Token found on window object!")
        setSupabaseToken(token)
        delete (window as any).SUPABASE_ACCESS_TOKEN
        clearInterval(intervalId)
      }
    }, 250)
    return () => clearInterval(intervalId)
  }, [])

  // Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ø¯Ù„ Ø§Ø² URL (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
  useEffect(() => {
    // Û±. ÛŒÚ© Ø§ÛŒÙ†ØªØ±ÙˆØ§Ù„ Ø¨Ø±Ø§ÛŒ Ú†Ú© Ú©Ø±Ø¯Ù† Ù…ØªØºÛŒØ± Ø³Ø±Ø§Ø³Ø±ÛŒ Ø¨Ø³Ø§Ø²
    const intervalId = setInterval(() => {
      // âœ…âœ…âœ… Ù„Ø§Ú¯ Ø§Ø´Ú©Ø§Ù„â€ŒØ²Ø¯Ø§ÛŒÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯ âœ…âœ…âœ…
      console.log(
        "DEBUG: Polling for token... Current window token:",
        (window as any).SUPABASE_ACCESS_TOKEN
      )

      // Û². Ú†Ú© Ú©Ù† Ø¢ÛŒØ§ Ù…ØªØºÛŒØ± ØªÙˆØ³Ø· React Native ØªØ²Ø±ÛŒÙ‚ Ø´Ø¯Ù‡ Ø§Ø³ØªØŸ
      if (
        typeof window !== "undefined" &&
        (window as any).SUPABASE_ACCESS_TOKEN
      ) {
        const token = (window as any).SUPABASE_ACCESS_TOKEN
        console.log("âœ…âœ…âœ… [WebView] SUCCESS! Token found on window object!")
        setSupabaseToken(token)

        // Û³. Ù…ØªØºÛŒØ± Ø±Ø§ Ù¾Ø§Ú© Ú©Ù† (Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø§Ù…Ø§ Ø§Ù…Ù†)
        delete (window as any).SUPABASE_ACCESS_TOKEN

        // Û´. Ø§ÛŒÙ†ØªØ±ÙˆØ§Ù„ Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ú©Ù†
        clearInterval(intervalId)
      } else {
        // Ûµ. ØªØ§ Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ ØªÙˆÚ©Ù† Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù‡ØŒ Ù„Ø§Ú¯ Ø¨Ø²Ù†
        console.log(
          "âŒ›ï¸ [WebView] Polling: window.SUPABASE_ACCESS_TOKEN not found yet..."
        )
      }
    }, 250) // Ù‡Ø± 250 Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡ Ú†Ú© Ú©Ù†

    return () => {
      clearInterval(intervalId) // Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø§ÛŒÙ†ØªØ±ÙˆØ§Ù„ Ø¯Ø± Ø²Ù…Ø§Ù† unmount
    }
  }, [])
  // ØªØ§Ø¨Ø¹ Ø¨Ø³ØªÙ† Ùˆ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ Ø§Ù¾ Ù†ÛŒØªÛŒÙˆ
  const closeWebView = () => {
    if (typeof window !== "undefined" && (window as any).ReactNativeWebView) {
      // âœ… [Ø§ØµÙ„Ø§Ø­] Ù…Ø§ Ù‡Ù†ÙˆØ² Ø¨Ø±Ø§ÛŒ Ø¨Ø³ØªÙ† Ø¨Ù‡ postMessage Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒÙ…
      ;(window as any).ReactNativeWebView.postMessage(
        JSON.stringify({ type: "close-webview" })
      )
    }
  }

  const stopRealtime = useCallback(() => {
    if (
      dataChannelRef.current &&
      dataChannelRef.current.readyState === "open"
    ) {
      console.log("â¡ï¸ Sending session.terminate event to OpenAI...")
      dataChannelRef.current.send(JSON.stringify({ type: "session.terminate" }))
    }

    if (dataChannelRef.current) {
      dataChannelRef.current.close()
      dataChannelRef.current = null
    }

    if (peerConnectionRef.current) {
      peerConnectionRef.current.close()
      peerConnectionRef.current = null
    }

    if (userStream) {
      userStream.getTracks().forEach(track => track.stop())
      setUserStream(null)
    }

    if (modelStream) {
      modelStream.getTracks().forEach(track => track.stop())
      setModelStream(null)
    }

    // Ø¨Ø³ØªÙ† ØªÙ…Ø§Ù… ØªÚ¯â€ŒÙ‡Ø§ÛŒ <audio> Ú©Ù‡ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
    document.querySelectorAll("audio").forEach(el => el.remove())

    setStatus("idle")
    console.log("ğŸ›‘ Realtime session stopped")
    closeWebView() // <-- Ø¨Ù‡ Ø§Ù¾ Ù†ÛŒØªÛŒÙˆ Ø§Ø·Ù„Ø§Ø¹ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø¨Ø³ØªÙ‡ Ø´ÙˆØ¯
  }, [userStream, modelStream])

  const startRealtime = useCallback(async () => {
    remoteLog("--- startRealtime function triggered ---")
    setStatus("connecting")
    let sessionData: any = null

    try {
      remoteLog("Reading token from window (using state)...")
      // â—ï¸â—ï¸â—ï¸ Ù…Ø§ Ù‡Ù…Ú†Ù†Ø§Ù† Ø§Ø² state Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†ÛŒÙ… Ú†ÙˆÙ† polling Ø¨Ø§ÛŒØ¯ Ø§ÙˆÙ„ ØªÙ…Ø§Ù… Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
      if (!supabaseToken) {
        remoteLog("FATAL: Token not found in state (supabaseToken is null).")
        throw new Error("Token not found in React state.")
      }

      remoteLog(`Token found in state. Calling /api/chat/openai...`)
      const res = await fetch("https://www.rhynoai.ir/api/chat/openai", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${supabaseToken}` // âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙˆÚ©Ù† state
        },
        body: JSON.stringify({ chatSettings: { model: model }, messages: [] })
      })

      remoteLog(`API call response status: ${res.status}`)
      if (!res.ok) {
        const errorData = await res.json()
        remoteLog(`API call failed: ${errorData.message}`)
        throw new Error(errorData.message || "Failed to get ephemeral key.")
      }

      sessionData = await res.json()
      remoteLog("Session data received from /api/chat.")

      // â—ï¸â—ï¸â—ï¸ [Ù„Ø§Ú¯ Û±: Ù¾Ø§Ø³Ø® Ú©Ø§Ù…Ù„ API Ø±Ø§ Ø¨Ø¨ÛŒÙ†ÛŒÙ…] â—ï¸â—ï¸â—ï¸
      console.log(
        "âœ… Session data received from /api/chat:",
        JSON.stringify(sessionData, null, 2)
      )

      // â—ï¸ Ø¨Ø± Ø§Ø³Ø§Ø³ route.ts Ø´Ù…Ø§ØŒ ØªÙˆÚ©Ù† Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯
      const EPHEMERAL_KEY = sessionData.client_secret?.value

      // â—ï¸â—ï¸â—ï¸ [Ù„Ø§Ú¯ Û²: Ø¨Ø¨ÛŒÙ†ÛŒÙ… ØªÙˆÚ©Ù† Ù¾ÛŒØ¯Ø§ Ø´Ø¯ ÛŒØ§ Ù†Ù‡] â—ï¸â—ï¸â—ï¸
      console.log(
        "ğŸ”‘ Extracted EPHEMERAL_KEY:",
        EPHEMERAL_KEY ? "Found" : "NOT FOUND"
      )

      if (!EPHEMERAL_KEY) {
        remoteLog("FATAL: client_secret not found in session data.")
        throw new Error("Invalid session data: client_secret.value is missing.")
      }
      remoteLog("Ephemeral key extracted. Setting up WebRTC...")
      const pc = new RTCPeerConnection()
      peerConnectionRef.current = pc

      pc.ontrack = e => {
        console.log("ğŸ”Š Remote audio track received:", e.streams)
        setModelStream(e.streams[0])

        // Ø­Ø°Ù <audio> Ù‚Ø¨Ù„ÛŒ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´Øª
        document
          .querySelectorAll("audio#model_audio")
          .forEach(el => el.remove())

        const audioEl = document.createElement("audio")
        audioEl.id = "model_audio" // ÛŒÚ© Ø¢ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù‡ØªØ±
        audioEl.srcObject = e.streams[0]
        audioEl.autoplay = true
        audioEl.setAttribute("playsinline", "true") // Ø¨Ø±Ø§ÛŒ iOS
        document.body.appendChild(audioEl)

        audioEl
          .play()
          .then(() => console.log("ğŸ”Š Model audio playing..."))
          .catch(err => {
            console.error("ğŸš¨ Autoplay blocked:", err)
            toast.error("Ù…Ø±ÙˆØ±Ú¯Ø± Ø§Ø¬Ø§Ø²Ù‡ Ù¾Ø®Ø´ Ø®ÙˆØ¯Ú©Ø§Ø± ØµØ¯Ø§ Ø±Ø§ Ù†Ø¯Ø§Ø¯.")
          })
      }

      const dc = pc.createDataChannel("oai-events")
      dataChannelRef.current = dc
      dc.onopen = () => console.log("ğŸ“¡ DataChannel opened:", dc.label)

      const buffers = new Map<string, string>()

      // Ûµ. ØªØ¹Ø±ÛŒÙ onmessage (Ù…Ù†Ø·Ù‚ ÙØ§Ù†Ú©Ø´Ù† Ú©Ø§Ù„ Ø´Ù…Ø§)
      dc.onmessage = async msg => {
        const data = JSON.parse(msg.data)

        if (data.type === "response.function_call_arguments.delta") {
          const id = data.tool_call_id || data.item_id
          if (!id) return
          const prev = buffers.get(id) ?? ""
          buffers.set(id, prev + (data.delta ?? ""))
        }

        if (data.type === "response.function_call_arguments.done") {
          const id = data.tool_call_id || data.item_id
          if (!id) return
          const buffer = buffers.get(id) ?? ""
          buffers.delete(id)
          if (!buffer.startsWith("{") || !buffer.endsWith("}")) return

          try {
            const args = JSON.parse(buffer)
            const query = args.query
            console.log("ğŸ” Search requested:", query)
            if (!query) return

            const searchRes = await fetch("/api/chat/search", {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ query })
            })

            const searchData = await searchRes.json()
            const textResult = searchData.output_text ?? "No result found."

            const payload = {
              type: "response.create",
              response: { conversation: "auto", instructions: textResult }
            }
            dc.send(JSON.stringify(payload))
            console.log("âœ… Sent search results back to model")
          } catch (err) {
            console.error("âŒ Error parsing JSON buffer:", buffer, err)
          }
        }

        if (data.type === "response.done") {
          console.log("âœ… Response.done received from OpenAI.")
        }
      } // Ù¾Ø§ÛŒØ§Ù† dc.onmessage

      pc.onconnectionstatechange = () => {
        console.log("âš¡ Connection state:", pc.connectionState)
        if (["disconnected", "failed", "closed"].includes(pc.connectionState)) {
          stopRealtime()
        }
      }

      // Û·. Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ú©Ø§Ø±Ø¨Ø±
      const ms = await navigator.mediaDevices.getUserMedia({
        audio: {
          noiseSuppression: true,
          echoCancellation: true
        }
      })
      console.log("ğŸ¤ Local stream obtained:", ms)
      setUserStream(ms)

      ms.getAudioTracks().forEach(track => {
        console.log("ğŸ¤ Sending audio track:", track.label)
        pc.addTrack(track, ms)
      })

      const offer = await pc.createOffer()
      await pc.setLocalDescription(offer)

      // Û¸. ØªØ¨Ø§Ø¯Ù„ SDP Ø¨Ø§ OpenAI
      const sdpResponse = await fetch(
        `https://api.openai.com/v1/realtime?model=${model}`,
        {
          method: "POST",
          body: offer.sdp,
          headers: {
            Authorization: `Bearer ${EPHEMERAL_KEY}`, // â—ï¸ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙˆÚ©Ù† OpenAI
            "Content-Type": "application/sdp"
          }
        }
      )

      if (!sdpResponse.ok) {
        throw new Error(`SDP exchange failed: ${sdpResponse.statusText}`)
      }

      const answer: RTCSessionDescriptionInit = {
        type: "answer",
        sdp: await sdpResponse.text()
      }
      await pc.setRemoteDescription(answer)
      setStatus("connected")
    } catch (error: any) {
      remoteLog(`!!! CATCH block error in startRealtime !!!: ${error.message}`)
      toast.error(`Ø®Ø·Ø§: ${error.message}`)
      stopRealtime()
    }
  }, [stopRealtime, model, supabaseToken])

  const handleIconClick = () => {
    if (status === "idle" && supabaseToken) {
      remoteLog("Icon clicked to start.") // <-- Ù„Ø§Ú¯ Ú©Ù„ÛŒÚ©
      startRealtime()
    } else if (status !== "idle") {
      remoteLog("Icon clicked to stop.") // <-- Ù„Ø§Ú¯ Ú©Ù„ÛŒÚ©
      stopRealtime()
    } else {
      remoteLog("Icon clicked, but token is not ready yet.") // <-- Ù„Ø§Ú¯ Ú©Ù„ÛŒÚ©
      toast.error("Ø¯Ø± Ø­Ø§Ù„ Ù‡Ù…Ú¯Ø§Ù…â€ŒØ³Ø§Ø²ÛŒ... Ù„Ø·ÙØ§Ù‹ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ ØµØ¨Ø± Ú©Ù†ÛŒØ¯.")
    }
  }
  // UI Ø±Ø§ Ø¯Ø± ÛŒÚ© div ØªÙ…Ø§Ù…â€ŒØµÙØ­Ù‡ Ø³ÛŒØ§Ù‡ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ… ØªØ§ Ø¨Ø§ Ø§Ù¾ Ù†ÛŒØªÛŒÙˆ ÛŒÚ©Ø³Ø§Ù† Ø¨Ø§Ø´Ø¯
  return (
    <div className="font-vazir fixed inset-0 bg-black text-white">
      {/* â—ï¸ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø®Ø·Ø§Ù‡Ø§ÛŒ toastØŒ Ø§ÛŒÙ† Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª Ù„Ø§Ø²Ù… Ø§Ø³Øª */}
      <Toaster position="top-center" richColors />

      <AnimatePresence>
        {status === "connected" && (
          <motion.div
            onClick={handleIconClick} // Ø¨Ø§ Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ù‡Ù… Ø¨Ø³ØªÙ‡ Ø´ÙˆØ¯
            className="fixed inset-0 z-50 flex cursor-pointer flex-col items-center justify-center bg-black/80 backdrop-blur-sm"
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            exit={{ opacity: 0 }}
            transition={{ duration: 0.3 }}
          >
            {/* Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª ÙˆÛŒÚ˜ÙˆØ§Ù„Ø§ÛŒØ²Ø± */}
            <CircularAudioVisualizer volume={combinedVolume} />

            <p className="mt-12 text-lg text-white">Ø¯Ø± Ø­Ø§Ù„ Ø´Ù†ÛŒØ¯Ù†...</p>
            <p className="mt-2 text-sm text-gray-400">
              Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ§Ù† Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯
            </p>
          </motion.div>
        )}
      </AnimatePresence>

      {/* Ø¨Ø®Ø´ UI Ø¯Ú©Ù…Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ (ÙˆÙ‚ØªÛŒ status !== 'connected') */}
      {status !== "connected" && (
        <div className="fixed bottom-12 left-1/2 z-50 flex -translate-x-1/2 flex-col items-center">
          <div
            onClick={handleIconClick}
            className={cn(
              "relative flex size-20 cursor-pointer items-center justify-center rounded-full transition-all duration-500",
              "bg-gradient-to-br from-blue-500 to-indigo-600 text-white",
              "shadow-lg shadow-blue-500/30",
              // âœ… [Ø§ØµÙ„Ø§Ø­ Ø§ØµÙ„ÛŒ Û´]
              // Ø¯Ú©Ù…Ù‡ Ø±Ø§ ØªØ§ Ø²Ù…Ø§Ù† Ø¯Ø±ÛŒØ§ÙØª ØªÙˆÚ©Ù† ØºÛŒØ±ÙØ¹Ø§Ù„ Ù†Ø´Ø§Ù† Ø¨Ø¯Ù‡
              !supabaseToken && "cursor-not-allowed opacity-50"
            )}
          >
            {status === "connecting" ? (
              // Ø¢ÛŒÚ©ÙˆÙ† Ù„ÙˆØ¯ÛŒÙ†Ú¯
              <svg
                className="size-10 animate-spin text-white"
                xmlns="http://www.w3.org/2000/svg"
                fill="none"
                viewBox="0 0 24 24"
              >
                <circle
                  className="opacity-25"
                  cx="12"
                  cy="12"
                  r="10"
                  stroke="currentColor"
                  strokeWidth="4"
                ></circle>
                <path
                  className="opacity-75"
                  fill="currentColor"
                  d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                ></path>
              </svg>
            ) : (
              // Ø¢ÛŒÚ©ÙˆÙ† Ù…ÛŒÚ©Ø±ÙˆÙÙˆÙ†
              <svg
                className="size-10 text-white"
                viewBox="0 0 24 24"
                fill="none"
                xmlns="http://www.w3.org/2000/svg"
              >
                <path
                  d="M12 1a3 3 0 00-3 3v8a3 3 0 006 0V4a3 3 0 00-3-3z"
                  fill="currentColor"
                />
                <path
                  d="M19 10v2a7 7 0 01-14 0v-2H3v2a9 9 0 008 8.94V23h2v-2.06A9 9 0 0021 12v-2h-2z"
                  fill="currentColor"
                />
              </svg>
            )}
          </div>
          <p className="mt-3 text-sm text-white">
            {status === "idle" && !supabaseToken && "Ø¯Ø± Ø­Ø§Ù„ Ù‡Ù…Ú¯Ø§Ù…â€ŒØ³Ø§Ø²ÛŒ..."}
            {status === "idle" && supabaseToken && "Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ ØµØ­Ø¨Øª Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯"}
            {status === "connecting" && "Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„..."}
          </p>
        </div>
      )}
    </div>
  )
}

// â—ï¸â—ï¸ [Ù…Ù‡Ù…] â—ï¸â—ï¸
// Ù…Ø§ Ø¨Ù‡ Ø§ÛŒÙ† Wrapper Ø¯ÛŒÚ¯Ø± Ù†ÛŒØ§Ø²ÛŒ Ù†Ø¯Ø§Ø±ÛŒÙ… Ú†ÙˆÙ† useSearchParams Ø­Ø°Ù Ø´Ø¯.
// Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª Ø§ØµÙ„ÛŒ Ø±Ø§ export Ú©Ù†ÛŒØ¯.
export default RealtimeVoicePage
