// Only used in use-chat-handler.tsx to keep it clean

import { createChatFiles } from "@/db/chat-files"
import { createChat } from "@/db/chats"
import { createMessageFileItems } from "@/db/message-file-items"
import { createMessages, updateMessage } from "@/db/messages"
import { uploadMessageImage } from "@/db/storage/message-images"
import {
  buildFinalMessages,
  adaptMessagesForGoogleGemini
} from "@/lib/build-prompt"
import { consumeReadableStream } from "@/lib/consume-stream"
import { Tables, TablesInsert } from "@/supabase/types"
import {
  ChatFile,
  ChatMessage,
  ChatPayload,
  ChatSettings,
  LLM,
  MessageImage
} from "@/types"
import React from "react"
import { toast } from "sonner"
import { v4 as uuidv4 } from "uuid"
import { supabase } from "@/lib/supabase/browser-client"

export const getAuthToken = async (): Promise<string | undefined> => {
  const {
    data: { session }
  } = await supabase.auth.getSession()
  return session?.access_token
}
export const validateChatSettings = (
  chatSettings: ChatSettings | null,
  modelData: LLM | undefined,
  profile: Tables<"profiles"> | null,
  selectedWorkspace: Tables<"workspaces"> | null,
  messageContent: string
) => {
  if (!chatSettings) {
    throw new Error("Chat settings not found")
  }

  if (!modelData) {
    throw new Error("Model not found")
  }

  if (!profile) {
    throw new Error("Profile not found")
  }

  if (!selectedWorkspace) {
    throw new Error("Workspace not found")
  }

  if (!messageContent) {
    throw new Error("Message content not found")
  }
}

export const handleRetrieval = async (
  userInput: string,
  newMessageFiles: ChatFile[],
  chatFiles: ChatFile[],
  embeddingsProvider: "openai" | "local",
  sourceCount: number
) => {
  const session = (await supabase.auth.getSession()).data.session
  if (!session) {
    throw new Error("User is not authenticated.")
  }
  const token = session.access_token
  console.log("TOKEN BEING SENT TO RETRIEVE:", token)
  const allFileIds = [
    ...newMessageFiles.map(file => file.id),
    ...chatFiles.map(file => file.id)
  ]
  const response = await fetch("/api/retrieval/retrieve", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      // Û³. Ù‡Ø¯Ø± Authorization Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
      Authorization: `Bearer ${token}`
    },
    body: JSON.stringify({
      userInput,
      fileIds: allFileIds,
      sourceCount
    })
  })

  // Û´. Ù…Ø¯ÛŒØ±ÛŒØª ØµØ­ÛŒØ­ Ø®Ø·Ø§Ù‡Ø§
  if (!response.ok) {
    const errorData = await response.json()
    console.error("Error retrieving:", response.status, errorData)
    throw new Error(
      errorData.message || `Failed to retrieve data (${response.status})`
    )
  }

  const json = await response.json()
  return json.results
}

export const createTempMessages = (
  messageContent: string,
  chatMessages: ChatMessage[],
  chatSettings: ChatSettings,
  // b64Images: string[], // âŒ Ø­Ø°Ù Ø´Ø¯
  newMessageImages: MessageImage[], // âœ¨ [Ø§ØµÙ„Ø§Ø­ Û±] Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
  isRegeneration: boolean,
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>,
  selectedAssistant: Tables<"assistants"> | null,
  setChatImages: React.Dispatch<React.SetStateAction<MessageImage[]>> // âœ¨ [Ø§ØµÙ„Ø§Ø­ Û²] Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
) => {
  // âœ¨ [Ø§ØµÙ„Ø§Ø­ Û³] ÛŒÚ© ID Ù…ÙˆÙ‚Øª Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ù… Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ…
  const tempMessageId = uuidv4()

  let tempUserChatMessage: ChatMessage = {
    message: {
      chat_id: "",
      assistant_id: null,
      content: messageContent,
      created_at: "",
      file_url: null,
      id: tempMessageId, // âœ¨ [Ø§ØµÙ„Ø§Ø­ Û´] Ø§Ø² ID Ù…ÙˆÙ‚Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
      image_paths: [], // Ø§ÛŒÙ† ØªÙˆØ³Ø· Ø§Ø³ØªÛŒØª chatImages Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒØ´ÙˆØ¯
      model: chatSettings.model,
      role: "user",
      sequence_number: chatMessages.length,
      updated_at: "",
      user_id: "",
      audio_url: ""
    },
    fileItems: []
  }

  let tempAssistantChatMessage: ChatMessage = {
    message: {
      chat_id: "",
      assistant_id: selectedAssistant?.id || null,
      content: "",
      created_at: "",
      file_url: null,
      id: uuidv4(),
      image_paths: [],
      model: chatSettings.model,
      role: "assistant",
      sequence_number: chatMessages.length + 1,
      updated_at: "",
      user_id: "",
      audio_url: ""
    },
    fileItems: []
  }

  // âœ¨ [Ø§ØµÙ„Ø§Ø­ Ûµ] Ø¨Ù„Ø§ÙØ§ØµÙ„Ù‡ Ø¹Ú©Ø³â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ‚Øª Ø±Ø§ Ø¨Ù‡ Ø§Ø³ØªÛŒØª chatImages Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
  // Ø§ÛŒÙ† Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª MessageImages Ø¢Ù†Ù‡Ø§ Ø±Ø§ ÙÙˆØ±Ø§Ù‹ Ø±Ù†Ø¯Ø± Ú©Ù†Ø¯
  const tempImages = newMessageImages.map(image => ({
    ...image,
    messageId: tempMessageId // Ø¹Ú©Ø³â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ Ù¾ÛŒØ§Ù… Ù…ÙˆÙ‚Øª Ù…ØªØµÙ„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
  }))

  if (!isRegeneration) {
    setChatImages(prev => [...prev, ...tempImages])
  }

  let newMessages = []

  if (isRegeneration) {
    const lastMessageIndex = chatMessages.length - 1
    chatMessages[lastMessageIndex].message.content = ""
    newMessages = [...chatMessages]
  } else {
    newMessages = [...chatMessages, tempAssistantChatMessage]
  }

  setChatMessages(newMessages)

  return {
    tempUserChatMessage,
    tempAssistantChatMessage
  }
}

export const handleLocalChat = async (
  payload: ChatPayload,
  profile: Tables<"profiles">,
  chatSettings: ChatSettings,
  tempAssistantMessage: ChatMessage,
  isRegeneration: boolean,
  newAbortController: AbortController,
  setIsGenerating: React.Dispatch<React.SetStateAction<boolean>>,
  setFirstTokenReceived: React.Dispatch<React.SetStateAction<boolean>>,
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>,
  setToolInUse: React.Dispatch<React.SetStateAction<string>>
) => {
  const formattedMessages = await buildFinalMessages(payload, profile, [])

  // Ollama API: https://github.com/jmorganca/ollama/blob/main/docs/api.md
  const response = await fetchChatResponse(
    process.env.NEXT_PUBLIC_OLLAMA_URL + "/api/chat",
    {
      model: chatSettings.model,
      messages: formattedMessages,
      options: {
        temperature: payload.chatSettings.temperature
      }
    },
    false,
    newAbortController,
    setIsGenerating,
    setChatMessages
  )

  return await processResponse(
    response,
    isRegeneration
      ? payload.chatMessages[payload.chatMessages.length - 1]
      : tempAssistantMessage,
    false,
    newAbortController,
    setFirstTokenReceived,
    setChatMessages,
    setToolInUse
  )
}

export const handleHostedChat = async (
  payload: ChatPayload,
  profile: Tables<"profiles">,
  modelData: LLM,
  chatId: string,
  tempAssistantChatMessage: ChatMessage,
  isRegeneration: boolean,

  newAbortController: AbortController,
  newMessageImages: MessageImage[],
  chatImages: MessageImage[],
  setIsGenerating: React.Dispatch<React.SetStateAction<boolean>>,
  setFirstTokenReceived: React.Dispatch<React.SetStateAction<boolean>>,
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>,
  setToolInUse: React.Dispatch<React.SetStateAction<string>>
) => {
  const provider =
    modelData.provider === "openai" && profile.use_azure_openai
      ? "azure"
      : modelData.provider

  const allImages = [...chatImages, ...newMessageImages]

  let draftMessages = await buildFinalMessages(payload, profile, allImages)

  let formattedMessages: any[] = []
  if (provider === "google") {
    formattedMessages = await adaptMessagesForGoogleGemini(
      payload,
      draftMessages
    )
  } else {
    formattedMessages = draftMessages
  }

  const apiEndpoint =
    provider === "custom" ? "/api/chat/custom" : `/api/chat/${provider}`

  const requestBody = {
    chatSettings: payload.chatSettings,
    messages: formattedMessages,
    customModelId: provider === "custom" ? modelData.hostedId : "",
    chat_id: chatId,
    is_user_message_saved: true
  }
  const token = await getAuthToken()
  const response = await fetchChatResponse(
    apiEndpoint,
    requestBody,
    true,
    newAbortController,
    setIsGenerating,
    setChatMessages,
    token
  )

  return await processResponse(
    response,
    isRegeneration
      ? payload.chatMessages[payload.chatMessages.length - 1]
      : tempAssistantChatMessage,
    true,
    newAbortController,
    setFirstTokenReceived,
    setChatMessages,
    setToolInUse
  )
}

export const fetchChatResponse = async (
  url: string,
  body: object,
  isHosted: boolean,
  controller: AbortController,
  setIsGenerating: React.Dispatch<React.SetStateAction<boolean>>,
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>,
  token?: string // âœ¨ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø§Ø®ØªÛŒØ§Ø±ÛŒ ØªÙˆÚ©Ù†
) => {
  const headers: HeadersInit = {
    "Content-Type": "application/json"
  }

  if (token) {
    headers["Authorization"] = `Bearer ${token}` // âœ¨ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù‡Ø¯Ø± Authorization
  }

  const response = await fetch(url, {
    method: "POST",
    headers,
    body: JSON.stringify(body),
    signal: controller.signal
  })

  if (!response.ok) {
    if (response.status === 404 && !isHosted) {
      toast.error(
        "Model not found. Make sure you have it downloaded via Ollama."
      )
    }

    const errorData = await response.json()
    toast.error(errorData.message)
    setIsGenerating(false)
    setChatMessages(prevMessages => prevMessages.slice(0, -2))
  }

  return response
}

export const processResponse = async (
  response: Response,
  lastChatMessage: ChatMessage,
  isHosted: boolean,
  controller: AbortController,
  setFirstTokenReceived: React.Dispatch<React.SetStateAction<boolean>>,
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>,
  setToolInUse: React.Dispatch<React.SetStateAction<string>>
): Promise<{ type: "text"; data: string } | { type: "image"; data: Blob }> => {
  const contentType = response.headers.get("content-type")

  // Ù…Ù†Ø·Ù‚ ØªØµÙˆÛŒØ± (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
  if (contentType && contentType.startsWith("image/")) {
    const imageBlob = await response.blob()
    setChatMessages(prev =>
      prev.map(chatMessage => {
        if (chatMessage.message.id === lastChatMessage.message.id) {
          return {
            ...chatMessage,
            message: {
              ...chatMessage.message,
              content: "[Image generated...]"
            }
          }
        }
        return chatMessage
      })
    )
    return { type: "image", data: imageBlob }
  }

  // âœ¨ [ØªØµØ­ÛŒØ­ Ù†Ù‡Ø§ÛŒÛŒ] Ù…Ù†Ø·Ù‚ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³ØªØ±ÛŒÙ… Ù…ØªÙ†
  if (response.body) {
    let fullText = ""
    let buffer = "" // Ø¨Ø§ÙØ± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ù…Ø­Ù„ÛŒ

    // console.log("Starting to process response stream...") // <-- Ù„Ø§Ú¯ Û±

    await consumeReadableStream(
      response.body,
      (chunk: string) => {
        setFirstTokenReceived(true)
        // console.log("STREAM CHUNK RECEIVED:", chunk) // <-- Ù„Ø§Ú¯ Û²: Ø§ÛŒÙ† Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ù„Ø§Ú¯ Ø§Ø³Øª

        if (isHosted) {
          // --- Ù…Ù†Ø·Ù‚ Ø¨Ø±Ø§ÛŒ Ø¨Ú©â€ŒØ§Ù†Ø¯ Ù…Ø§ (OpenAI/route.ts) ---
          let currentChunk = chunk
          let textReceived = false

          // Û±. Ú†Ú© Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¢ÛŒØ§ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¯Ø± Ø§ÛŒÙ† Ú†Ø§Ù†Ú© ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŸ
          if (currentChunk.includes("%%TOOL_CALL:search%%")) {
            // console.log("âœ… Search signal detected!") // <-- Ù„Ø§Ú¯ Û³
            setToolInUse("search")
            // Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø±Ø§ Ø§Ø² Ú†Ø§Ù†Ú© Ø­Ø°Ù Ú©Ù† ØªØ§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù†Ø´ÙˆØ¯
            currentChunk = currentChunk.replace("%%TOOL_CALL:search%%", "")
          }

          // Û². Ø¢ÛŒØ§ Ù…ØªÙ†ÛŒ (Ø¨Ù‡ Ø¬Ø² Ø³ÛŒÚ¯Ù†Ø§Ù„) Ø¯Ø± Ú†Ø§Ù†Ú© Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡ Ø§Ø³ØªØŸ
          if (currentChunk.length > 0) {
            // console.log("Text content detected in chunk.") // <-- Ù„Ø§Ú¯ Û´
            setToolInUse("none") // ÙˆØ¶Ø¹ÛŒØª Ø±Ø§ Ø¨Ù‡ "Ø¯Ø± Ø­Ø§Ù„ ØªØ§ÛŒÙ¾" Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
            fullText += currentChunk
            textReceived = true
          }

          // (Ø§Ú¯Ø± Ú†Ø§Ù†Ú© *ÙÙ‚Ø·* Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨ÙˆØ¯ØŒ `currentChunk.length` ØµÙØ± Ø§Ø³ØªØŒ
          // `setToolInUse("none")` ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ "Searching" Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯)
        } else {
          // --- Ù…Ù†Ø·Ù‚ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ (Ollama) ---
          buffer += chunk
          let contentToAdd = ""
          try {
            contentToAdd = buffer
              .trimEnd()
              .split("\n")
              .reduce((acc, line) => acc + JSON.parse(line).message.content, "")
            buffer = ""
            setToolInUse("none")
            fullText += contentToAdd
          } catch (error) {
            // JSON Ú©Ø§Ù…Ù„ Ù†ÛŒØ³ØªØŒ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†
          }
        }

        // Ø¢Ù¾Ø¯ÛŒØª UI
        setChatMessages(prev =>
          prev.map(chatMessage => {
            if (chatMessage.message.id === lastChatMessage.message.id) {
              return {
                ...chatMessage,
                message: { ...chatMessage.message, content: fullText }
              }
            }
            return chatMessage
          })
        )
      },
      controller.signal
    )

    // console.log("Stream processing finished.") // <-- Ù„Ø§Ú¯ Ûµ
    return { type: "text", data: fullText }
  } else {
    console.error("Response body is null")
    return { type: "text", data: "" }
  }
}

export const handleCreateChat = async (
  chatSettings: ChatSettings,
  profile: Tables<"profiles">,
  selectedWorkspace: Tables<"workspaces">,
  messageContent: string,
  selectedAssistant: Tables<"assistants">,
  newMessageFiles: ChatFile[],
  setSelectedChat: React.Dispatch<React.SetStateAction<Tables<"chats"> | null>>,
  setChats: React.Dispatch<React.SetStateAction<Tables<"chats">[]>>,
  setChatFiles: React.Dispatch<React.SetStateAction<ChatFile[]>>
) => {
  const createdChat = await createChat({
    user_id: profile.user_id,
    workspace_id: selectedWorkspace.id,
    assistant_id: selectedAssistant?.id || null,
    context_length: chatSettings.contextLength,
    include_profile_context: chatSettings.includeProfileContext,
    include_workspace_instructions: chatSettings.includeWorkspaceInstructions,
    model: chatSettings.model,
    name: messageContent.substring(0, 100),
    prompt: chatSettings.prompt,
    temperature: chatSettings.temperature,
    embeddings_provider: chatSettings.embeddingsProvider
  })

  setSelectedChat(createdChat)
  setChats(chats => [createdChat, ...chats])

  await createChatFiles(
    newMessageFiles.map(file => ({
      user_id: profile.user_id,
      chat_id: createdChat.id,
      file_id: file.id
    }))
  )

  setChatFiles(prev => [...prev, ...newMessageFiles])

  return createdChat
}

export const handleCreateMessages = async (
  chatMessages: ChatMessage[],
  currentChat: Tables<"chats">,
  profile: Tables<"profiles">,
  modelData: LLM,
  messageContent: string,
  generatedText: string,
  assistantFileUrl: string | null, // âœ¨ ØªØ±ØªÛŒØ¨ ØµØ­ÛŒØ­ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
  newMessageImages: MessageImage[],
  isRegeneration: boolean,
  retrievedFileItems: Tables<"file_items">[],
  setChatMessages: React.Dispatch<React.SetStateAction<ChatMessage[]>>,
  setChatFileItems: React.Dispatch<
    React.SetStateAction<Tables<"file_items">[]>
  >,
  setChatImages: React.Dispatch<React.SetStateAction<MessageImage[]>>,
  selectedAssistant: Tables<"assistants"> | null
) => {
  const sanitizedMessageContent = messageContent.replace(
    /[\u200B-\u200D\uFEFF]/g,
    ""
  )
  const userTimestamp = new Date().toISOString()
  const assistantTimestamp = new Date(
    new Date(userTimestamp).getTime() + 1000
  ).toISOString()
  // --- ğŸ‘†ğŸ‘†ğŸ‘† ---.

  const finalUserMessage: TablesInsert<"messages"> = {
    chat_id: currentChat.id,
    assistant_id: null,
    user_id: profile.user_id,
    content: sanitizedMessageContent,
    model: modelData.modelId,
    role: "user",
    sequence_number: chatMessages.length,
    image_paths: [],
    file_url: null,
    created_at: userTimestamp
  }

  const finalAssistantMessage: TablesInsert<"messages"> = {
    chat_id: currentChat.id,
    assistant_id: selectedAssistant?.id || null,
    user_id: profile.user_id,
    content: generatedText.trim() === "" ? " " : generatedText,
    model: modelData.modelId,
    role: "assistant",
    sequence_number: chatMessages.length + 1,
    image_paths: [],
    file_url: assistantFileUrl,
    created_at: assistantTimestamp
  }

  let finalChatMessages: ChatMessage[] = []

  if (isRegeneration) {
    const lastMessage = chatMessages[chatMessages.length - 1]
    if (lastMessage.message.role === "assistant") {
      // âœ¨ Ø§ØµÙ„Ø§Ø­: Ø¯Ø± Ø²Ù…Ø§Ù† Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒØŒ file_url Ø±Ø§ Ù‡Ù… Ø¢Ù¾Ø¯ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
      const updatedMessage = await updateMessage(lastMessage.message.id, {
        content: generatedText,
        file_url: assistantFileUrl
      })
      chatMessages[chatMessages.length - 1].message = updatedMessage
      setChatMessages([...chatMessages])
    }
  } else {
    // âœ¨ Ø§ØµÙ„Ø§Ø­: Ù…Ù†Ø·Ù‚ Ú©Ø§Ù…Ù„ Ø¨Ù„ÙˆÚ© else Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ…
    const createdMessages = await createMessages([
      finalUserMessage,
      finalAssistantMessage
    ])

    // Upload each image (stored in newMessageImages) for the user message to message_images bucket
    const uploadPromises = newMessageImages
      .filter(obj => obj.file !== null)
      .map(obj => {
        let filePath = `${profile.user_id}/${currentChat.id}/${
          createdMessages[0].id
        }/${uuidv4()}`

        return uploadMessageImage(filePath, obj.file as File).catch(error => {
          console.error(`Failed to upload image at ${filePath}:`, error)
          return null
        })
      })

    const paths = (await Promise.all(uploadPromises)).filter(
      Boolean
    ) as string[]

    setChatImages(prevImages => [
      ...prevImages,
      ...newMessageImages.map((obj, index) => ({
        ...obj,
        messageId: createdMessages[0].id,
        path: paths[index]
      }))
    ])

    const updatedMessage = await updateMessage(createdMessages[0].id, {
      ...createdMessages[0],
      image_paths: paths
    })

    const createdMessageFileItems = await createMessageFileItems(
      retrievedFileItems.map(fileItem => {
        return {
          user_id: profile.user_id,
          message_id: createdMessages[1].id,
          file_item_id: fileItem.id
        }
      })
    )

    finalChatMessages = [
      ...chatMessages,
      {
        message: updatedMessage,
        fileItems: []
      },
      {
        message: createdMessages[1],
        fileItems: retrievedFileItems.map(fileItem => fileItem.id)
      }
    ]

    setChatFileItems(prevFileItems => {
      const newFileItems = retrievedFileItems.filter(
        fileItem => !prevFileItems.some(prevItem => prevItem.id === fileItem.id)
      )

      return [...prevFileItems, ...newFileItems]
    })

    setChatMessages(finalChatMessages)
  }
}
