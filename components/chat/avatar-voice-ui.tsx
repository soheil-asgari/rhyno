"use client"
import { FC, useState, useRef, useCallback, useEffect, useContext } from "react"
import { ChatbotUIContext } from "@/context/context"
import { cn } from "@/lib/utils"
import { toast } from "sonner"
import { motion, AnimatePresence } from "framer-motion"
import { CircularAudioVisualizer } from "./CircularAudioVisualizer"
import { supabase } from "@/lib/supabase/client"

interface VoiceUIProps {
  chatSettings: any
}

// âœ¨ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ø®Ø·Ø§Ù‡Ø§ÛŒ import Ùˆ Ù…Ø³ØªÙ‚Ù„ Ø´Ø¯Ù† Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª
const useAudioVisualizer = (stream: MediaStream | null) => {
  const [volume, setVolume] = useState(0)
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyzerRef = useRef<AnalyserNode | null>(null)
  const dataArrayRef = useRef<Uint8Array | null>(null)

  useEffect(() => {
    if (!stream) {
      if (audioContextRef.current) {
        audioContextRef.current.close()
        audioContextRef.current = null
      }
      return
    }

    if (!audioContextRef.current) {
      const audioContext = new (window.AudioContext ||
        (window as any).webkitAudioContext)()
      const analyzer = audioContext.createAnalyser()
      analyzer.fftSize = 256
      const source = audioContext.createMediaStreamSource(stream)
      source.connect(analyzer)
      analyzerRef.current = analyzer
      dataArrayRef.current = new Uint8Array(analyzer.frequencyBinCount)
      audioContextRef.current = audioContext
    }
    const analyze = () => {
      const analyzer = analyzerRef.current
      const dataArray = dataArrayRef.current

      if (analyzer && dataArray) {
        // Ø§ÛŒØ¬Ø§Ø¯ Uint8Array ÙˆØ§Ù‚Ø¹ÛŒ Ø±ÙˆÛŒ ArrayBuffer Ø¬Ø¯ÛŒØ¯
        const buffer = new ArrayBuffer(dataArray.length)
        const typedArray = new Uint8Array(buffer)
        typedArray.set(dataArray) // Ú©Ù¾ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Uint8Array Ø¬Ø¯ÛŒØ¯

        analyzer.getByteFrequencyData(typedArray)

        const sum = typedArray.reduce((a, b) => a + b, 0)
        const avg = sum / typedArray.length
        setVolume(avg)
      }

      requestAnimationFrame(analyze)
    }

    analyze()

    return () => {
      if (audioContextRef.current) {
        audioContextRef.current.close()
        audioContextRef.current = null
      }
    }
  }, [stream])

  return volume
}

const getUserAccessToken = async (): Promise<string | null> => {
  try {
    // 2. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„Ø§ÛŒÙ†Øª Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø´Ø¯Ù‡
    const {
      data: { session },
      error
    } = await supabase.auth.getSession()

    if (error) {
      console.error("Supabase getSession error:", error)
      return null
    }

    if (session) {
      return session.access_token
    }

    return null
  } catch (err) {
    console.error("Error fetching user token:", err)
    return null
  }
}
export const AvatarVoiceUI: FC<VoiceUIProps> = ({ chatSettings }) => {
  const fullContextValue = useContext(ChatbotUIContext)
  // console.log("CONTEXT VALUE RECEIVED:", fullContextValue)
  const { setIsSpeechPlaying, setModelVolume } = fullContextValue
  const [status, setStatus] = useState<"idle" | "connecting" | "connected">(
    "idle"
  )

  const dataChannelRef = useRef<RTCDataChannel | null>(null)

  const [userStream, setUserStream] = useState<MediaStream | null>(null)
  const [modelStream, setModelStream] = useState<MediaStream | null>(null)

  const peerConnectionRef = useRef<RTCPeerConnection | null>(null)

  const userVolume = useAudioVisualizer(userStream)
  const modelVolume = useAudioVisualizer(modelStream)
  const combinedVolume = Math.max(userVolume, modelVolume)
  useEffect(() => {
    const volumeThreshold = 5 // Ø¢Ø³ØªØ§Ù†Ù‡ Ø³Ú©ÙˆØª (Ø§ÛŒÙ† Ø¹Ø¯Ø¯ Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯)

    if (modelVolume > volumeThreshold) {
      setIsSpeechPlaying(true)
    } else {
      setIsSpeechPlaying(false)
    }

    // Ø§Ø±Ø³Ø§Ù„ Ù…Ø³ØªÙ‚ÛŒÙ… ÙˆÙ„ÙˆÙ… Ø¨Ù‡ Ú©Ø§Ù†ØªÚ©Ø³Øª Ø¨Ø±Ø§ÛŒ Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ù†Ø±Ù…
    if (setModelVolume) {
      setModelVolume(modelVolume)
    }
  }, [modelVolume, setIsSpeechPlaying, setModelVolume])
  const stopRealtime = useCallback(() => {
    if (
      dataChannelRef.current &&
      dataChannelRef.current.readyState === "open"
    ) {
      // console.log("â¡ï¸ Sending session.terminate event to OpenAI...")
      dataChannelRef.current.send(JSON.stringify({ type: "session.terminate" }))
    }

    if (dataChannelRef.current) {
      dataChannelRef.current.close()
      dataChannelRef.current = null
    }

    if (peerConnectionRef.current) {
      peerConnectionRef.current.close()
      peerConnectionRef.current = null
    }

    if (userStream) {
      userStream.getTracks().forEach(track => track.stop())
      setUserStream(null)
    }

    if (modelStream) {
      modelStream.getTracks().forEach(track => track.stop())
      setModelStream(null)
    }
    setIsSpeechPlaying(false)
    setStatus("idle")
    // console.log("ğŸ›‘ Realtime session stopped")
  }, [userStream, modelStream, setIsSpeechPlaying])

  const startRealtime = useCallback(
    async (model: string) => {
      setStatus("connecting")

      // âœ¨ Ù…ØªØºÛŒØ± sessionData Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø³Ø·Ø­ scope ØªØ§Ø¨Ø¹ ØªØ¹Ø±ÛŒÙ Ø´ÙˆØ¯
      // ØªØ§ Ù‡Ù… Ø¯Ø± Ø¨Ù„Ø§Ú© try Ùˆ Ù‡Ù… Ø¯Ø± dc.onmessage Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ø§Ø´Ø¯
      let sessionData: any = null

      try {
        // 1. Ø§ÙˆÙ„ ØªÙˆÚ©Ù† Ø±Ø§ Ø¨Ú¯ÛŒØ±
        const token = await getUserAccessToken()
        if (!token) {
          throw new Error("User not authenticated. Missing access token.")
        }

        // 2. Ø­Ø§Ù„Ø§ Ø¨Ø§ Ø³Ø±ÙˆØ± Ø®ÙˆØ¯Øª ØªÙ…Ø§Ø³ Ø¨Ú¯ÛŒØ± ØªØ§ session Ø±Ø§ Ø¨Ø³Ø§Ø²ÛŒ
        //    (Ø§ÛŒÙ† Ù‡Ù…Ø§Ù† Ú©Ø¯ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø´Ù…Ø§ Ø¨Ù‡ Ø§Ø´ØªØ¨Ø§Ù‡ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù‡ Ø¨ÙˆØ¯ÛŒØ¯)
        const res = await fetch("/api/chat/openai", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${token}` // âœ¨ ØªÙˆÚ©Ù† Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
          },
          body: JSON.stringify({
            chatSettings: chatSettings // Ø§Ø±Ø³Ø§Ù„ Ú©Ù„ Ø¢Ø¨Ø¬Ú©Øª chatSettings
          })
        })

        if (!res.ok) {
          const errorData = await res.json()
          throw new Error(errorData.message || "Failed to get ephemeral key.")
        }

        // 3. Ø­Ø§Ù„Ø§ sessionData Ø±Ø§ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ú©Ù†
        sessionData = await res.json()
        try {
          // console.log(
          //   `âœ… Session created (${sessionData.id}). Waiting 1 sec for OpenAI to provision...`
          // )
          await new Promise(resolve => setTimeout(resolve, 1000)) // 1 Ø«Ø§Ù†ÛŒÙ‡ ØµØ¨Ø± Ú©Ù†
          console.log("...Waited 1 sec. Attempting SDP exchange.")
        } catch (e) {
          // console.error("Error during delay", e)
        }
        // 4. Ø­Ø§Ù„Ø§ Ú©Ù‡ sessionData Ø±Ø§ Ø¯Ø§Ø±ÛŒÙ…ØŒ WebRTC Ø±Ø§ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù†
        const pc = new RTCPeerConnection()
        peerConnectionRef.current = pc

        pc.ontrack = e => {
          console.log("ğŸ”Š Remote audio track received:", e.streams)
          setModelStream(e.streams[0])

          const audioEl = document.createElement("audio")
          audioEl.srcObject = e.streams[0]
          audioEl.autoplay = true
          audioEl.setAttribute("playsinline", "true")

          document.body.appendChild(audioEl)

          audioEl
            .play()
            .then(() => {
              // console.log("ğŸ”Š Model audio playing...")
            })
            .catch(err => {
              // console.error("ğŸš¨ Autoplay blocked:", err)
            })
        }

        const dc = pc.createDataChannel("oai-events")
        dataChannelRef.current = dc
        dc.onopen = () => {
          // console.log("ğŸ“¡ DataChannel opened:", dc.label)
        }

        const buffers = new Map<string, string>()

        // 5. Ø­Ø§Ù„Ø§ onmessage Ø±Ø§ ØªØ¹Ø±ÛŒÙ Ú©Ù†
        //    (Ú†ÙˆÙ† sessionData Ø¯Ø± scope Ø¨Ø§Ù„Ø§ØªØ± ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ØŒ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø§Ø¨Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø³Øª)
        dc.onmessage = async msg => {
          const data = JSON.parse(msg.data)
          // console.log("ğŸ“© RAW event:", data)

          if (data.type === "response.function_call_arguments.delta") {
            // ... (Ú©Ø¯ Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…Ø´Ú©Ù„ÛŒ Ù†Ø¯Ø§Ø´Øª)
            const id = data.tool_call_id || data.item_id
            if (!id) {
              console.warn("âš ï¸ No tool_call_id or item_id in delta:", data)
              return
            }
            // console.log("ğŸ†” Using buffer id:", id, " | delta:", data.delta)
            const prev = buffers.get(id) ?? ""
            buffers.set(id, prev + (data.delta ?? ""))
            // console.log("âœï¸ Partial buffer for", id, ":", buffers.get(id))
          }

          if (data.type === "response.function_call_arguments.done") {
            // ... (Ú©Ø¯ Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…Ø´Ú©Ù„ÛŒ Ù†Ø¯Ø§Ø´Øª)
            const id = data.tool_call_id || data.item_id
            if (!id) {
              console.warn("âš ï¸ No tool_call_id or item_id in done:", data)
              return
            }
            // console.log("ğŸ†” Finalizing buffer for id:", id)
            const buffer = buffers.get(id) ?? ""
            buffers.delete(id)
            // console.log("âœ… Final buffer (raw):", buffer)
            if (!buffer.startsWith("{") || !buffer.endsWith("}")) {
              // console.warn("âš ï¸ Incomplete JSON, skipping:", buffer)
              return
            }
            try {
              const args = JSON.parse(buffer)
              const query = args.query
              // console.log("ğŸ” Search requested:", query)
              if (!query) return
              const token = await getUserAccessToken()
              if (!token) {
                console.error("âŒ Cannot search: User token is null.")
                return // Ø§Ú¯Ø± ØªÙˆÚ©Ù† Ù†Ø¨ÙˆØ¯ØŒ Ù…ØªÙˆÙ‚Ù Ø´Ùˆ
              }
              // console.log("ğŸŒ Sending query to /api/chat/search ...")
              const searchRes = await fetch("/api/chat/search", {
                method: "POST",
                headers: {
                  "Content-Type": "application/json",
                  // âœ… Û². ØªÙˆÚ©Ù† Ø±Ø§ Ø¨Ù‡ Ù‡Ø¯Ø± Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
                  Authorization: `Bearer ${token}`
                },
                body: JSON.stringify({ query })
              })
              // console.log("ğŸŒ Got response, status:", searchRes.status)
              const data = await searchRes.json()
              // console.log("ğŸ“¥ Search API raw response:", data)
              const textResult = data.output_text ?? "No result found."
              let payload
              if (data.tool_call_id) {
                payload = {
                  type: "response.create",
                  response: { conversation: "auto", instructions: textResult }
                }
              } else {
                payload = {
                  type: "response.create",
                  response: { conversation: "auto", instructions: textResult }
                }
              }
              // console.log(
              //   "ğŸ“¦ Payload to realtime:",
              //   JSON.stringify(payload, null, 2)
              // )
              dc.send(JSON.stringify(payload))
              // console.log("âœ… Sent results back to model")
            } catch (err) {
              console.error("âŒ Error parsing JSON buffer:", buffer, err)
            }
          }

          // 6. Ø§ÛŒÙ† Ø¨Ù„Ø§Ú© "done" (Ø§Ø±Ø³Ø§Ù„ usage) Ø§Ø³Øª
          if (data.type === "response.done" && data.response?.usage) {
            const usageData = data.response.usage // <-- 'usage' Ø§ÛŒÙ†Ø¬Ø§ ØªØ¹Ø±ÛŒÙ Ù…ÛŒâ€ŒØ´ÙˆØ¯
            // console.log(`ğŸ” Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙˆÚ©Ù† Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù¾Ø§Ø³Ø®:`)
            // console.log(`- ÙˆØ±ÙˆØ¯ÛŒ: ${usageData.input_tokens} ØªÙˆÚ©Ù†`)
            // console.log(`- Ø®Ø±ÙˆØ¬ÛŒ: ${usageData.output_tokens} ØªÙˆÚ©Ù†`)

            // âœ¨ 7. Ø§ÛŒÙ†Ø¬Ø§ Ø±Ø§Ù‡â€ŒØ­Ù„ Ù‚Ø¨Ù„ÛŒ (Ú¯Ø±ÙØªÙ† ØªÙˆÚ©Ù† ØªØ§Ø²Ù‡) Ø±Ø§ Ø§Ø¹Ù…Ø§Ù„ Ú©Ù†
            try {
              const currentToken = await getUserAccessToken() // <-- ØªÙˆÚ©Ù† ØªØ§Ø²Ù‡
              if (!currentToken) {
                console.error(
                  "âŒ Could not get user token before sending usage data."
                )
                throw new Error("Missing user token for usage report.")
              }

              // Ù†Ø§Ù… Ù…ØªØºÛŒØ± Ø±Ø§ Ø¹ÙˆØ¶ Ú©Ù† Ú©Ù‡ Ø¨Ø§ res Ø¨Ø§Ù„Ø§ ØªØ¯Ø§Ø®Ù„ Ù†Ú©Ù†Ø¯
              const webhookRes = await fetch("/api/chat/openai", {
                // âœ… Û±. Ø¢Ø¯Ø±Ø³ ØµØ­ÛŒØ­
                method: "POST",
                headers: {
                  "Content-Type": "application/json",
                  Authorization: `Bearer ${currentToken}`
                },
                body: JSON.stringify({
                  // âœ… Û². Ø¨Ø¯Ù†Ù‡ ØµØ­ÛŒØ­
                  isUsageReport: true,
                  modelId: chatSettings.model,
                  usage: {
                    input_tokens: usageData.input_tokens,
                    output_tokens: usageData.output_tokens
                  }
                })
              })

              if (!webhookRes.ok) {
                console.error("âŒ Error sending usage data to temporary API.")
              }
            } catch (error) {
              console.error("âŒ Network error sending usage data:", error)
            }
          }
        } // Ù¾Ø§ÛŒØ§Ù† dc.onmessage

        pc.onconnectionstatechange = () => {
          // console.log("âš¡ Connection state:", pc.connectionState)
          if (
            ["disconnected", "failed", "closed"].includes(pc.connectionState)
          ) {
            stopRealtime()
          }
        }

        const ms = await navigator.mediaDevices.getUserMedia({
          audio: {
            noiseSuppression: true,
            echoCancellation: true
          }
        })
        // console.log("ğŸ¤ Local stream obtained:", ms)
        setUserStream(ms)

        ms.getAudioTracks().forEach(track => {
          // console.log("ğŸ¤ Sending audio track:", track.label, track.readyState)
          pc.addTrack(track, ms)
        })

        // console.log("ğŸ¤ Local stream tracks:", ms.getTracks())

        const offer = await pc.createOffer()
        await pc.setLocalDescription(offer)

        // 8. Ø­Ø§Ù„Ø§ Ø§Ø² sessionData Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        const sessionId = sessionData.id
        const EPHEMERAL_KEY = sessionData.client_secret?.value

        // Û±. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø² Ø³Ø±ÙˆØ±
        const actualModelId = sessionData.model

        if (!sessionId || !EPHEMERAL_KEY || !actualModelId) {
          throw new Error("Session data from backend is incomplete.")
        }

        const sdpResponse = await fetch(
          `https://api.openai.com/v1/realtime?model=${model}`,
          {
            method: "POST",
            body: offer.sdp,
            headers: {
              Authorization: `Bearer ${EPHEMERAL_KEY}`,
              "Content-Type": "application/sdp"
            }
          }
        )

        if (!sdpResponse.ok) {
          throw new Error(`SDP exchange failed: ${sdpResponse.statusText}`)
        }

        const answer: RTCSessionDescriptionInit = {
          type: "answer",
          sdp: await sdpResponse.text()
        }
        await pc.setRemoteDescription(answer)
        setStatus("connected")
        console.log("âœ… Realtime session started")
      } catch (error) {
        console.error(
          `âŒ Could not start voice chat: ${
            error instanceof Error ? error.message : "Unknown error"
          }`
        )
        stopRealtime()
      }
    },
    [stopRealtime, chatSettings]
  )

  const handleIconClick = () => {
    if (status === "idle") {
      startRealtime(chatSettings.model)
    } else {
      stopRealtime()
    }
  }

  return (
    <>
      {/* Ø¨Ø®Ø´ UI Ø¯Ú©Ù…Ù‡ Ø§ÙˆÙ„ÛŒÙ‡ (ÙˆÙ‚ØªÛŒ status !== 'connected') */}
      <div className="fixed bottom-12 left-1/2 z-50 flex -translate-x-1/2 flex-col items-center">
        <div
          onClick={handleIconClick}
          className={cn(
            "relative flex cursor-pointer items-center justify-center rounded-full transition-all duration-500",
            // â—ï¸ Û². Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ status ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯
            status === "connected"
              ? "bg-gradient-to-br from-red-500 to-red-700 text-white" // Ù‚Ø±Ù…Ø² Ù‡Ù†Ú¯Ø§Ù… Ø§ØªØµØ§Ù„
              : "bg-gradient-to-br from-[#4facfe] to-[#8e2de2] text-white", // Ø¢Ø¨ÛŒ/Ø¨Ù†ÙØ´
            "shadow-[0_8px_16px_rgba(0,0,0,0.3)] dark:shadow-[0_8px_16px_rgba(0,0,0,0.5)]",
            "size-20"
          )}
        >
          {/* â—ï¸ Û³. Ù…Ø­ØªÙˆØ§ÛŒ Ø¯Ú©Ù…Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ status */}
          {status === "connecting" && (
            <svg
              className="size-8 animate-spin"
              /* ... (Ø¢ÛŒÚ©ÙˆÙ† Ù„ÙˆØ¯ÛŒÙ†Ú¯ Ø´Ù…Ø§) ... */ fill="none"
              viewBox="0 0 24 24"
              stroke="currentColor"
            >
              <path
                strokeLinecap="round"
                strokeLinejoin="round"
                strokeWidth={2}
                d="M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9M4 12v5h.582m15.356 2A8.001 8.001 0 004.582 15"
              />
            </svg>
          )}
          {status === "idle" && (
            <span className="text-4xl">â€¢â€¢â€¢â€¢</span> // Ø­Ø§Ù„Øª Ø¢Ù…Ø§Ø¯Ù‡
          )}
          {status === "connected" && (
            <span className="icon-stop-class">â– </span> // Ø­Ø§Ù„Øª Ù…ØªØµÙ„ (Ø§Ø² Ø¢ÛŒÚ©ÙˆÙ† Ø®ÙˆØ¯ØªØ§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯)
          )}
        </div>
        <p className="font-vazir mt-3 text-sm text-white">
          {/* â—ï¸ Û´. Ù…ØªÙ† Ø²ÛŒØ± Ø¯Ú©Ù…Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ status */}
          {status === "idle" && "Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ ØµØ­Ø¨Øª Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯"}
          {status === "connecting" && "Ø¯Ø± Ø­Ø§Ù„ Ø§ØªØµØ§Ù„..."}
          {status === "connected" && "Ø¯Ø± Ø­Ø§Ù„ Ù…Ú©Ø§Ù„Ù…Ù‡ (Ø¨Ø±Ø§ÛŒ ØªÙˆÙ‚Ù Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯)"}
        </p>
      </div>
    </>
  )
}
